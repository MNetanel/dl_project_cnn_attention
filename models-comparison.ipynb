{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.utils.data\nimport torchvision.datasets\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom tqdm import tqdm\nfrom copy import deepcopy\nfrom collections import OrderedDict","metadata":{"id":"20i9dQgTTahN","execution":{"iopub.status.busy":"2023-07-19T18:35:36.522493Z","iopub.execute_input":"2023-07-19T18:35:36.522934Z","iopub.status.idle":"2023-07-19T18:35:36.533653Z","shell.execute_reply.started":"2023-07-19T18:35:36.522897Z","shell.execute_reply":"2023-07-19T18:35:36.532650Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# tools used or loading cifar10 dataset\nfrom torchvision.datasets import CIFAR10\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\nfrom torchvision import transforms\n\n\ndef get_dataloader(dataset, batch_size, return_numpy=False):\n    collate_fn = numpy_collate_fn if return_numpy else None\n    train_dataloader      = DataLoader(dataset=dataset[\"train\"], batch_size=batch_size, shuffle=True, drop_last=True,\n                                       collate_fn=collate_fn)\n    validation_dataloader = DataLoader(dataset=dataset[\"validation\"], batch_size=batch_size, shuffle=False, drop_last=False,\n                                       collate_fn=collate_fn)\n    test_dataloader       = DataLoader(dataset=dataset[\"test\"], batch_size=batch_size, shuffle=False, drop_last=False,\n                                       collate_fn=collate_fn)\n    return {\"train\": train_dataloader, \"validation\": validation_dataloader, \"test\": test_dataloader}\n\n\ndef numpy_collate_fn(batch):\n    imgs = torch.stack([b[0] for b in batch], dim=0).numpy()\n    labels = np.array([b[1] for b in batch], dtype=np.int32)\n    return imgs, labels\n\n\ndef read_data_sets(data_dir, validation_size=5000):\n    \"\"\"\n    Returns the dataset readed from data_dir.\n    Uses or not uses one-hot encoding for the labels.\n    Subsamples validation set with specified size if necessary.\n    Args:\n      data_dir: Data directory.\n      one_hot: Flag for one hot encoding.\n      validation_size: Size of validation set\n    Returns:\n      Dictionary with Train, Validation, Test Datasets\n    \"\"\"\n\n    mean = (0.491, 0.482, 0.447)\n    std  = (0.247, 0.243, 0.262)\n\n    data_transforms = transforms.Compose([\n                            transforms.ToTensor(),\n                            transforms.Normalize(mean, std)\n                        ])\n\n    train_dataset = CIFAR10(root=data_dir, train=True, download=True, transform=data_transforms)\n    test_dataset = CIFAR10(root=data_dir, train=False, download=True, transform=data_transforms)\n\n    # Subsample the validation set from the train set\n    if not 0 <= validation_size <= len(train_dataset):\n        raise ValueError(\"Validation size should be between 0 and {0}. Received: {1}.\".format(\n            len(train_dataset), validation_size))\n\n    train_dataset, validation_dataset = random_split(train_dataset,\n                                                     lengths=[len(train_dataset) - validation_size, validation_size],\n                                                     generator=torch.Generator().manual_seed(42))\n\n    return {'train': train_dataset, 'validation': validation_dataset, 'test': test_dataset}\n\n\ndef get_cifar10(data_dir='data/', validation_size=5000):\n    \"\"\"\n    Prepares CIFAR10 dataset.\n    Args:\n      data_dir: Data directory.\n      one_hot: Flag for one hot encoding.\n      validation_size: Size of validation set\n    Returns:\n      Dictionary with Train, Validation, Test Datasets\n    \"\"\"\n    return read_data_sets(data_dir, validation_size)","metadata":{"id":"0rOe9P9Ymnmq","execution":{"iopub.status.busy":"2023-07-19T18:35:36.861835Z","iopub.execute_input":"2023-07-19T18:35:36.862919Z","iopub.status.idle":"2023-07-19T18:35:36.885448Z","shell.execute_reply.started":"2023-07-19T18:35:36.862881Z","shell.execute_reply":"2023-07-19T18:35:36.884407Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Seed for reproduceability\nseed = 42\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.determinstic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(42)\n\n# Setup device-agnostic code\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7M0lsnssT8B5","outputId":"253b6e3e-9cc4-4055-872f-8ea7bf1b5b6a","execution":{"iopub.status.busy":"2023-07-19T18:35:37.714602Z","iopub.execute_input":"2023-07-19T18:35:37.715452Z","iopub.status.idle":"2023-07-19T18:35:37.731164Z","shell.execute_reply.started":"2023-07-19T18:35:37.715412Z","shell.execute_reply":"2023-07-19T18:35:37.730221Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"cifar10 = get_cifar10()\ncifar10_loader = get_dataloader(cifar10, 128)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lGQcyxykmy76","outputId":"6b1154a6-2add-4a82-a5c1-36977b4acc46","execution":{"iopub.status.busy":"2023-07-19T18:35:38.725204Z","iopub.execute_input":"2023-07-19T18:35:38.725665Z","iopub.status.idle":"2023-07-19T18:35:40.517209Z","shell.execute_reply.started":"2023-07-19T18:35:38.725608Z","shell.execute_reply":"2023-07-19T18:35:40.516175Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"# transform = transforms.Compose([\n#     transforms.ToTensor(),\n#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n# ])\n\n# cifar10_train = torchvision.datasets.CIFAR10(root='data', train=True, transform=transform, download=True)\n# cifar10_valid = torchvision.datasets.CIFAR10(root='data', train=False, transform=transform, download=True)\n# cifar10_test = torchvision.datasets.CIFAR10(root='data', train=False, transform=transform, download=True)\n# cifar10_loader_train = torch.utils.data.DataLoader(cifar10_train, batch_size=128, shuffle=True)\n# cifar10_loader_valid = torch.utils.data.DataLoader(cifar10_valid, batch_size=128, shuffle=False)\n# cifar10_loader_test = torch.utils.data.DataLoader(cifar10_test, batch_size=128, shuffle=False)\n# cifar10_loader = {'train': cifar10_loader_train, 'validation': cifar10_loader_valid, 'test': cifar10_loader_test}","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5sZmIXwPTlem","outputId":"477595fc-06e3-494c-cbd9-25cfe3c0e2a5","execution":{"iopub.status.busy":"2023-07-19T18:35:40.519355Z","iopub.execute_input":"2023-07-19T18:35:40.519821Z","iopub.status.idle":"2023-07-19T18:35:40.525165Z","shell.execute_reply.started":"2023-07-19T18:35:40.519786Z","shell.execute_reply":"2023-07-19T18:35:40.524162Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def make_plots(logging_dict, model_name, avg_train=True):\n#     logging_dict = {'loss': {'train': [], 'validation': []},\n#                 'accuracy': {'train': [], 'validation': []},\n#                 'lr': [],\n#                 'batches_per_epoch': [],}\n    epoch_ends = np.cumsum(logging_dict['batches_per_epoch'])\n\n    def get_avg_per_epoch(batch_data):\n        result = [None,]\n        for i in range(len(epoch_ends) - 1):\n            result.append(np.average(batch_data[epoch_ends[i]:epoch_ends[i + 1]]))\n        return result\n\n    fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n    metrics = ('loss', 'accuracy')\n    for metric, ax in zip(metrics, axes.ravel()):\n#         ax.plot(logging_dict[metric]['train'])\n        if avg_train:\n            ax.plot(get_avg_per_epoch(logging_dict[metric]['train']), '.-', label='training set')\n            ax.plot(logging_dict[metric]['validation'], '.-', label='validation set')\n            ax.set(title=metric, xlabel='epoch', xticks=np.arange(len(epoch_ends)))\n        else:\n            ax.plot(logging_dict[metric]['train'],'.-', label='training set')\n            ax.plot(epoch_ends, logging_dict[metric]['validation'],'.-', label='validation set')\n            ax.set(title=metric, xlabel='batch')\n\n    handles, labels = ax.get_legend_handles_labels()\n    plt.figlegend(handles=handles, labels=labels, loc='upper center', bbox_to_anchor=(0.5, 0), ncol=2)\n    plt.suptitle(model_name)\n    plt.tight_layout()\n    plt.show()","metadata":{"id":"cfeGG_jQUDDh","execution":{"iopub.status.busy":"2023-07-19T18:35:41.194331Z","iopub.execute_input":"2023-07-19T18:35:41.195285Z","iopub.status.idle":"2023-07-19T18:35:41.207653Z","shell.execute_reply.started":"2023-07-19T18:35:41.195239Z","shell.execute_reply":"2023-07-19T18:35:41.206358Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, data_loader):\n    \"\"\"\n    Performs the evaluation of the MLP model on a given dataset.\n\n    Args:\n      model: An instance of 'MLP', the model to evaluate.\n      data_loader: The data loader of the dataset to evaluate.\n    Returns:\n        accuracy\n    \"\"\"\n    accuracies_per_batch, losses_per_batch = [], []\n    loss_module = nn.CrossEntropyLoss()\n    # Get accuracy for epoch\n    for batch in data_loader:\n\n        # Get validation images and labels\n        X = batch[0].to(device)\n        y = batch[1].to(device)\n\n        # Get predictions on validation set\n        model.eval()\n        with torch.no_grad():\n            pred_logits = model.forward(X)\n            pred_classes = torch.argmax(torch.softmax(pred_logits, dim=1), axis=1)\n\n        # Calculate accuracy := # of correct preds / total # of preds\n        current_accuracy = torch.sum(pred_classes == y) / pred_classes.shape[0]\n        accuracies_per_batch.append(current_accuracy.item())\n        current_loss = loss_module(pred_logits, y).item()\n        losses_per_batch.append(current_loss)\n\n    accuracy = np.average(accuracies_per_batch)\n    loss = np.average(losses_per_batch)\n\n    return accuracy, loss","metadata":{"id":"Duu0UPmhUMXr","execution":{"iopub.status.busy":"2023-07-19T18:35:42.577948Z","iopub.execute_input":"2023-07-19T18:35:42.578358Z","iopub.status.idle":"2023-07-19T18:35:42.587308Z","shell.execute_reply.started":"2023-07-19T18:35:42.578324Z","shell.execute_reply":"2023-07-19T18:35:42.586284Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def train(model, epochs=15, lr=0.1, momentum=0, verbose=True):\n\n    logging_dict = {'loss': {'train': [], 'validation': []},\n                    'accuracy': {'train': [], 'validation': []},\n                    'lr': [],\n                    'batches_per_epoch': [],\n                    'momentum': momentum}\n\n    for epoch in tqdm(range(epochs)):\n\n        batches_per_epoch = 0\n\n        model.train()\n\n        # Loss module and optimizer\n        loss_module = nn.CrossEntropyLoss()\n        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n\n\n        for batch in cifar10_loader['train']:\n\n            batches_per_epoch += 1\n\n            # Get training images and labels\n            X_train = batch[0].to(device)\n            y_train = batch[1].to(device)\n\n            # Forward pass\n            train_pred_logits = model.forward(X_train)\n\n            # Calculate loss\n            loss = loss_module(train_pred_logits, y_train)\n            logging_dict['loss']['train'].append(loss.item())\n\n            # Calculate accuracy\n            train_pred_class = torch.argmax(torch.softmax(train_pred_logits, dim=1), axis=1)\n            train_accuracy = torch.sum(train_pred_class == y_train) / train_pred_class.shape[0]\n            logging_dict['accuracy']['train'].append(train_accuracy.item())\n\n            # Zero gradients\n            optimizer.zero_grad()\n\n            # Backward pass\n            loss.backward()\n\n            # Update parameters\n            optimizer.step()\n\n\n        # Log num of batches for this epoch\n        logging_dict['batches_per_epoch'].append(batches_per_epoch)\n\n        # Log current LR\n        logging_dict['lr'].append(optimizer.param_groups[0]['lr'])\n\n        # Update LR\n        scheduler.step(loss)\n\n        # Get metrics on validation set\n        validation_accuracy, validation_loss = evaluate_model(model, cifar10_loader['validation'])\n        logging_dict['accuracy']['validation'].append(validation_accuracy.item())\n        logging_dict['loss']['validation'].append(validation_loss.item())\n\n        # Determine if best model\n        if len(logging_dict['accuracy']['validation']) == 1 or \\\n            all([validation_accuracy > acc for acc in logging_dict['accuracy']['validation']]):\n            best_model = deepcopy(model)\n\n        if verbose:\n            print(f'\\n{epoch = }, '\n                  f'training accuracy: {train_accuracy.item():.3f}, '\n                  f'training loss: {loss.item():.3f}',\n                  f'validation accuracy: {validation_accuracy.item():.3f}, '\n                  f'validation loss: {validation_loss.item():.3f}',\n                 )\n\n    # Get metrics on test set\n    test_accuracy, test_loss = evaluate_model(best_model, cifar10_loader['test'])\n\n    return best_model, test_accuracy, test_loss, logging_dict","metadata":{"id":"nrmqS372UPZF","execution":{"iopub.status.busy":"2023-07-19T18:37:37.317320Z","iopub.execute_input":"2023-07-19T18:37:37.318564Z","iopub.status.idle":"2023-07-19T18:37:37.338000Z","shell.execute_reply.started":"2023-07-19T18:37:37.318523Z","shell.execute_reply":"2023-07-19T18:37:37.336899Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"---\n\nModel\n---\n\n","metadata":{"id":"4qsz_zl9UnAO"}},{"cell_type":"code","source":"class Cifar10CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(3, 64, 3, padding=1)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(64)),\n            ('conv2', nn.Conv2d(64, 64, 3)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(64)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25))\n        ]))\n        self.layer2 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(64, 128, 3, padding=1)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(128)),\n            ('conv2', nn.Conv2d(128, 128, 3)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(128)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25))\n        ]))\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(128 * 6 * 6, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, 10)\n        self.softmax = nn.Softmax(1)\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.softmax(x)\n        return x","metadata":{"id":"qK4LJ8VjU1at","execution":{"iopub.status.busy":"2023-07-19T18:37:38.976319Z","iopub.execute_input":"2023-07-19T18:37:38.977066Z","iopub.status.idle":"2023-07-19T18:37:38.992644Z","shell.execute_reply.started":"2023-07-19T18:37:38.977027Z","shell.execute_reply":"2023-07-19T18:37:38.991446Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model = Cifar10CNN().to(device)\nbest_model, test_accuracy, test_loss, logging_dict = train(model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGlZCa_LYlo8","outputId":"604772f5-f73e-41db-9d16-d877cb017642","execution":{"iopub.status.busy":"2023-07-19T18:37:42.755840Z","iopub.execute_input":"2023-07-19T18:37:42.756304Z","iopub.status.idle":"2023-07-19T18:41:27.858356Z","shell.execute_reply.started":"2023-07-19T18:37:42.756250Z","shell.execute_reply":"2023-07-19T18:41:27.857344Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"  7%|▋         | 1/15 [00:14<03:29, 14.96s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 0, training accuracy: 0.422, training loss: 2.009 validation accuracy: 0.498, validation loss: 1.965\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 2/15 [00:30<03:19, 15.37s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 1, training accuracy: 0.492, training loss: 1.974 validation accuracy: 0.544, validation loss: 1.920\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 3/15 [00:44<02:58, 14.88s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 2, training accuracy: 0.586, training loss: 1.881 validation accuracy: 0.637, validation loss: 1.829\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 4/15 [01:00<02:46, 15.12s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 3, training accuracy: 0.625, training loss: 1.835 validation accuracy: 0.645, validation loss: 1.816\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 5/15 [01:15<02:29, 14.95s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 4, training accuracy: 0.711, training loss: 1.744 validation accuracy: 0.671, validation loss: 1.787\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 6/15 [01:30<02:14, 14.97s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 5, training accuracy: 0.711, training loss: 1.759 validation accuracy: 0.693, validation loss: 1.768\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 7/15 [01:44<01:59, 14.95s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 6, training accuracy: 0.750, training loss: 1.709 validation accuracy: 0.721, validation loss: 1.742\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 8/15 [01:59<01:44, 14.88s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 7, training accuracy: 0.727, training loss: 1.732 validation accuracy: 0.740, validation loss: 1.722\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 9/15 [02:15<01:30, 15.02s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 8, training accuracy: 0.750, training loss: 1.712 validation accuracy: 0.744, validation loss: 1.715\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 10/15 [02:29<01:13, 14.78s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 9, training accuracy: 0.734, training loss: 1.722 validation accuracy: 0.751, validation loss: 1.709\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 11/15 [02:44<00:59, 14.84s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 10, training accuracy: 0.680, training loss: 1.778 validation accuracy: 0.756, validation loss: 1.708\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 12/15 [02:58<00:43, 14.64s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 11, training accuracy: 0.773, training loss: 1.676 validation accuracy: 0.762, validation loss: 1.698\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 13/15 [03:13<00:29, 14.69s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 12, training accuracy: 0.781, training loss: 1.673 validation accuracy: 0.773, validation loss: 1.689\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 14/15 [03:27<00:14, 14.50s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 13, training accuracy: 0.766, training loss: 1.691 validation accuracy: 0.782, validation loss: 1.682\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 15/15 [03:42<00:00, 14.83s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 14, training accuracy: 0.797, training loss: 1.665 validation accuracy: 0.784, validation loss: 1.676\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n\n---\n\n\n\n---\n\n","metadata":{"id":"P2-oqoU8jawO"}},{"cell_type":"markdown","source":"https://github.com/chenjie/PyTorch-CIFAR-10-autoencoder/blob/master/main.py","metadata":{"id":"EhXV0nJIlAbv"}},{"cell_type":"code","source":"class Autoencoder(nn.Module):\n    def __init__(self, in_channels, out_channels, importance=1, k=3, s=2, p=1, **kwargs):\n        super(Autoencoder, self).__init__()\n        self.importance = importance\n        self.encoder = nn.Sequential(\n            nn.Conv2d(in_channels, 12, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(12, 24, 4, stride=2, padding=1),\n            nn.ReLU(),\n\t\t\tnn.Conv2d(24, 48, 4, stride=2, padding=1),\n            nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),\n            nn.ReLU(),\n\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(12, out_channels, k, stride=s, padding=p, **kwargs),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded * x * self.importance","metadata":{"id":"3r2kLBu5lFV0","execution":{"iopub.status.busy":"2023-07-19T18:41:27.860621Z","iopub.execute_input":"2023-07-19T18:41:27.860997Z","iopub.status.idle":"2023-07-19T18:41:27.870618Z","shell.execute_reply.started":"2023-07-19T18:41:27.860963Z","shell.execute_reply":"2023-07-19T18:41:27.869608Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class AECifar10CNN(nn.Module):\n    def __init__(self, importance=[1, 1]):\n        super().__init__()\n        self.layer1 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(3, 64, 3, padding=1)),\n            ('ae1', Autoencoder(64, 64, output_padding=1)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(64)),\n            ('conv2', nn.Conv2d(64, 64, 3)),\n            ('ae2', Autoencoder(64, 64, k=3, s=3, p=3)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(64)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n        ]))\n        self.layer2 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(64, 128, 3, padding=1)),\n            ('ae1', Autoencoder(128, 128, s=4, output_padding=2)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(128)),\n            ('conv2', nn.Conv2d(128, 128, 3)),\n            ('ae2', Autoencoder(128, 128, k=2, s=4, output_padding=1)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(128)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n        ]))\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(128 * 6 * 6, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, 10)\n        self.softmax = nn.Softmax(1)\n        self.importance = importance\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.softmax(x)\n        return x","metadata":{"id":"2uypPkOkjbeQ","execution":{"iopub.status.busy":"2023-07-19T18:41:27.871961Z","iopub.execute_input":"2023-07-19T18:41:27.872604Z","iopub.status.idle":"2023-07-19T18:41:27.890264Z","shell.execute_reply.started":"2023-07-19T18:41:27.872570Z","shell.execute_reply":"2023-07-19T18:41:27.889220Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"ae_model = AECifar10CNN().to(device)\nbest_ae_model, ae_test_accuracy, ae_test_loss, ae_logging_dict = train(ae_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QYTD4ZCgn8Aw","outputId":"95e8d686-acd2-4397-bb01-8823a8ad4f6d","execution":{"iopub.status.busy":"2023-07-19T18:41:27.893189Z","iopub.execute_input":"2023-07-19T18:41:27.893556Z","iopub.status.idle":"2023-07-19T18:45:57.941744Z","shell.execute_reply.started":"2023-07-19T18:41:27.893508Z","shell.execute_reply":"2023-07-19T18:45:57.940506Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"  7%|▋         | 1/15 [00:17<04:10, 17.89s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 0, training accuracy: 0.438, training loss: 2.011 validation accuracy: 0.485, validation loss: 1.969\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 2/15 [00:36<04:00, 18.49s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 1, training accuracy: 0.578, training loss: 1.877 validation accuracy: 0.568, validation loss: 1.890\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 3/15 [00:55<03:43, 18.65s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 2, training accuracy: 0.523, training loss: 1.928 validation accuracy: 0.644, validation loss: 1.816\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 4/15 [01:13<03:23, 18.52s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 3, training accuracy: 0.680, training loss: 1.772 validation accuracy: 0.681, validation loss: 1.785\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 5/15 [01:31<03:02, 18.27s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 4, training accuracy: 0.789, training loss: 1.695 validation accuracy: 0.688, validation loss: 1.776\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 6/15 [01:49<02:41, 17.98s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 5, training accuracy: 0.680, training loss: 1.773 validation accuracy: 0.710, validation loss: 1.752\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 7/15 [02:06<02:23, 17.90s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 6, training accuracy: 0.711, training loss: 1.760 validation accuracy: 0.719, validation loss: 1.739\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 8/15 [02:24<02:03, 17.69s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 7, training accuracy: 0.695, training loss: 1.771 validation accuracy: 0.739, validation loss: 1.720\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 9/15 [02:42<01:46, 17.73s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 8, training accuracy: 0.766, training loss: 1.696 validation accuracy: 0.737, validation loss: 1.726\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 10/15 [02:59<01:27, 17.56s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 9, training accuracy: 0.750, training loss: 1.711 validation accuracy: 0.750, validation loss: 1.712\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 11/15 [03:16<01:10, 17.58s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 10, training accuracy: 0.680, training loss: 1.767 validation accuracy: 0.747, validation loss: 1.711\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 12/15 [03:34<00:52, 17.54s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 11, training accuracy: 0.695, training loss: 1.751 validation accuracy: 0.763, validation loss: 1.701\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 13/15 [03:51<00:35, 17.53s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 12, training accuracy: 0.719, training loss: 1.738 validation accuracy: 0.762, validation loss: 1.702\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 14/15 [04:09<00:17, 17.58s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 13, training accuracy: 0.789, training loss: 1.673 validation accuracy: 0.776, validation loss: 1.684\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 15/15 [04:26<00:00, 17.78s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 14, training accuracy: 0.773, training loss: 1.676 validation accuracy: 0.783, validation loss: 1.677\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# autoencoder = Autoencoder().to(device)\n\n# # Define an optimizer and criterion\n# criterion = nn.BCELoss()\n# optimizer = torch.optim.Adam(autoencoder.parameters())\n\n# for epoch in tqdm(range(50)):\n#         running_loss = 0.0\n#         for i, (inputs, _) in enumerate(cifar10_loader['train'], 0):\n#             inputs = inputs.to(device)\n\n#             # ============ Forward ============\n#             encoded, outputs = autoencoder(inputs)\n#             loss = criterion(outputs, inputs)\n#             # ============ Backward ============\n#             optimizer.zero_grad()\n#             loss.backward()\n#             optimizer.step()\n\n#             # ============ Logging ============\n#             # running_loss += loss.data\n\n#         print(f'{epoch + 1, i + 1} {loss: .3f}')\n#         # running_loss = 0.0","metadata":{"id":"SRkxvLW_uE63","execution":{"iopub.status.busy":"2023-07-19T18:35:33.997694Z","iopub.status.idle":"2023-07-19T18:35:33.999072Z","shell.execute_reply.started":"2023-07-19T18:35:33.998820Z","shell.execute_reply":"2023-07-19T18:35:33.998843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n---\n\n","metadata":{"id":"I9qGfSBS71lt"}},{"cell_type":"code","source":"class eca_layer(nn.Module):\n    \"\"\"Constructs a ECA module.\n\n    Args:\n        channel: Number of channels of the input feature map\n        k_size: Adaptive selection of kernel size\n    \"\"\"\n    def __init__(self, channel, k_size=3):\n        super(eca_layer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # feature descriptor on the global spatial information\n        y = self.avg_pool(x)\n\n        # Two different branches of ECA module\n        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)\n\n        # Multi-scale information fusion\n        y = self.sigmoid(y)\n\n        return x * y.expand_as(x)","metadata":{"id":"LHRQi2ML72A_","execution":{"iopub.status.busy":"2023-07-19T18:45:57.943343Z","iopub.execute_input":"2023-07-19T18:45:57.943737Z","iopub.status.idle":"2023-07-19T18:45:57.952039Z","shell.execute_reply.started":"2023-07-19T18:45:57.943702Z","shell.execute_reply":"2023-07-19T18:45:57.950915Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class ECACifar10CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(3, 64, 3, padding=1)),\n            ('eca1', eca_layer(64)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(64)),\n            ('conv2', nn.Conv2d(64, 64, 3)),\n            ('eca2', eca_layer(64)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(64)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n        ]))\n        self.layer2 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(64, 128, 3, padding=1)),\n            ('eca1', eca_layer(128)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(128)),\n            ('conv2', nn.Conv2d(128, 128, 3)),\n            ('eca2', eca_layer(128)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(128)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n        ]))\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(128 * 6 * 6, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, 10)\n        self.softmax = nn.Softmax(1)\n\n    def forward(self, x):\n        # print(x.shape, self.ae(x)[1].shape)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.softmax(x)\n        return x","metadata":{"id":"_oMjawcy79Ez","execution":{"iopub.status.busy":"2023-07-19T18:45:57.953570Z","iopub.execute_input":"2023-07-19T18:45:57.953958Z","iopub.status.idle":"2023-07-19T18:45:57.969565Z","shell.execute_reply.started":"2023-07-19T18:45:57.953925Z","shell.execute_reply":"2023-07-19T18:45:57.968513Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"eca_model = ECACifar10CNN().to(device)\nbest_eca_model, eca_test_accuracy, eca_test_loss, eca_logging_dict = train(eca_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-KJRIsdt8Mm7","outputId":"cd1a0a38-bb9d-4d59-a51c-a380472caab4","execution":{"iopub.status.busy":"2023-07-19T18:45:57.970841Z","iopub.execute_input":"2023-07-19T18:45:57.971239Z","iopub.status.idle":"2023-07-19T18:49:42.870636Z","shell.execute_reply.started":"2023-07-19T18:45:57.971207Z","shell.execute_reply":"2023-07-19T18:49:42.869646Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"  7%|▋         | 1/15 [00:15<03:30, 15.04s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 0, training accuracy: 0.398, training loss: 2.069 validation accuracy: 0.468, validation loss: 1.994\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 2/15 [00:29<03:12, 14.83s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 1, training accuracy: 0.555, training loss: 1.903 validation accuracy: 0.541, validation loss: 1.918\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 3/15 [00:44<02:59, 14.92s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 2, training accuracy: 0.641, training loss: 1.829 validation accuracy: 0.646, validation loss: 1.815\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 4/15 [00:59<02:43, 14.86s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 3, training accuracy: 0.594, training loss: 1.860 validation accuracy: 0.667, validation loss: 1.791\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 5/15 [01:15<02:32, 15.23s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 4, training accuracy: 0.617, training loss: 1.837 validation accuracy: 0.696, validation loss: 1.763\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 6/15 [01:29<02:14, 14.98s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 5, training accuracy: 0.688, training loss: 1.765 validation accuracy: 0.704, validation loss: 1.757\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 7/15 [01:44<01:59, 15.00s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 6, training accuracy: 0.672, training loss: 1.782 validation accuracy: 0.725, validation loss: 1.735\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 8/15 [01:59<01:43, 14.82s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 7, training accuracy: 0.711, training loss: 1.746 validation accuracy: 0.744, validation loss: 1.715\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 9/15 [02:13<01:28, 14.71s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 8, training accuracy: 0.719, training loss: 1.732 validation accuracy: 0.756, validation loss: 1.707\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 10/15 [02:28<01:14, 14.81s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 9, training accuracy: 0.812, training loss: 1.661 validation accuracy: 0.767, validation loss: 1.695\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 11/15 [02:43<00:59, 14.78s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 10, training accuracy: 0.727, training loss: 1.738 validation accuracy: 0.771, validation loss: 1.690\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 12/15 [02:58<00:44, 14.87s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 11, training accuracy: 0.820, training loss: 1.656 validation accuracy: 0.783, validation loss: 1.683\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 13/15 [03:13<00:29, 14.71s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 12, training accuracy: 0.773, training loss: 1.685 validation accuracy: 0.781, validation loss: 1.683\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 14/15 [03:27<00:14, 14.76s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 13, training accuracy: 0.734, training loss: 1.730 validation accuracy: 0.791, validation loss: 1.672\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 15/15 [03:42<00:00, 14.82s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 14, training accuracy: 0.773, training loss: 1.670 validation accuracy: 0.784, validation loss: 1.680\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n\n---\n\n\n\n---\n\n","metadata":{"id":"E_oA4yTREsjk"}},{"cell_type":"code","source":"class AECACifar10CNN(nn.Module):\n    def __init__(self, importance=[1, 1]):\n        super().__init__()\n        self.layer1 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(3, 64, 3, padding=1)),\n            ('eca1', eca_layer(64)),\n            ('ae1', Autoencoder(64, 64, output_padding=1)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(64)),\n            ('conv2', nn.Conv2d(64, 64, 3)),\n            ('eca2', eca_layer(64)),\n            ('ae2', Autoencoder(64, 64, k=3, s=3, p=3)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(64)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n        ]))\n        self.layer2 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(64, 128, 3, padding=1)),\n            ('eca1', eca_layer(128)),\n            ('ae1', Autoencoder(128, 128, s=4, output_padding=2)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(128)),\n            ('conv2', nn.Conv2d(128, 128, 3)),\n            ('eca2', eca_layer(128)),\n            ('ae2', Autoencoder(128, 128, k=2, s=4, output_padding=1)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(128)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n        ]))\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(128 * 6 * 6, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, 10)\n        self.softmax = nn.Softmax(1)\n        self.importance = importance\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.softmax(x)\n        return x","metadata":{"id":"CQtPLdEdEtJe","execution":{"iopub.status.busy":"2023-07-19T18:49:42.871980Z","iopub.execute_input":"2023-07-19T18:49:42.872861Z","iopub.status.idle":"2023-07-19T18:49:42.889465Z","shell.execute_reply.started":"2023-07-19T18:49:42.872826Z","shell.execute_reply":"2023-07-19T18:49:42.888430Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"aeca_model = AECACifar10CNN().to(device)\nbest_aeca_model, aeca_test_accuracy, aeca_test_loss, aeca_logging_dict = train(aeca_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iTXMgFpdEySJ","outputId":"77e2ae6e-2142-4806-dfa7-5767863007f2","execution":{"iopub.status.busy":"2023-07-19T18:49:42.890943Z","iopub.execute_input":"2023-07-19T18:49:42.891413Z","iopub.status.idle":"2023-07-19T18:54:17.001744Z","shell.execute_reply.started":"2023-07-19T18:49:42.891358Z","shell.execute_reply":"2023-07-19T18:54:17.000616Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"  7%|▋         | 1/15 [00:18<04:17, 18.37s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 0, training accuracy: 0.523, training loss: 1.945 validation accuracy: 0.547, validation loss: 1.919\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 2/15 [00:36<03:55, 18.10s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 1, training accuracy: 0.578, training loss: 1.867 validation accuracy: 0.631, validation loss: 1.836\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 3/15 [00:54<03:38, 18.21s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 2, training accuracy: 0.664, training loss: 1.807 validation accuracy: 0.647, validation loss: 1.816\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 4/15 [01:12<03:19, 18.18s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 3, training accuracy: 0.664, training loss: 1.800 validation accuracy: 0.694, validation loss: 1.766\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 5/15 [01:30<02:59, 17.98s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 4, training accuracy: 0.695, training loss: 1.761 validation accuracy: 0.712, validation loss: 1.752\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 6/15 [01:48<02:42, 18.04s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 5, training accuracy: 0.680, training loss: 1.786 validation accuracy: 0.735, validation loss: 1.726\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 7/15 [02:06<02:23, 17.92s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 6, training accuracy: 0.742, training loss: 1.716 validation accuracy: 0.742, validation loss: 1.723\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 8/15 [02:24<02:06, 18.04s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 7, training accuracy: 0.664, training loss: 1.795 validation accuracy: 0.743, validation loss: 1.716\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 9/15 [02:42<01:47, 17.95s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 8, training accuracy: 0.773, training loss: 1.691 validation accuracy: 0.757, validation loss: 1.706\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 10/15 [03:00<01:30, 18.03s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 9, training accuracy: 0.789, training loss: 1.688 validation accuracy: 0.751, validation loss: 1.708\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 11/15 [03:18<01:12, 18.11s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 10, training accuracy: 0.789, training loss: 1.673 validation accuracy: 0.776, validation loss: 1.688\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 12/15 [03:36<00:53, 18.00s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 11, training accuracy: 0.820, training loss: 1.643 validation accuracy: 0.777, validation loss: 1.685\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 13/15 [03:54<00:36, 18.03s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 12, training accuracy: 0.773, training loss: 1.697 validation accuracy: 0.787, validation loss: 1.678\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 14/15 [04:12<00:17, 17.97s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 13, training accuracy: 0.812, training loss: 1.652 validation accuracy: 0.788, validation loss: 1.674\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 15/15 [04:30<00:00, 18.06s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 14, training accuracy: 0.844, training loss: 1.636 validation accuracy: 0.801, validation loss: 1.662\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"Bze0PgiYFChF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n---\n\n","metadata":{"id":"W0qUhJZPF589"}},{"cell_type":"code","source":"def conv1x1(in_planes: int, out_planes: int, stride: int = 1, bias=False) -> nn.Conv2d:\n    '''1x1 convolution'''\n    return nn.Conv2d(\n        in_planes,\n        out_planes,\n        kernel_size=1,\n        stride=stride,\n        bias=bias\n    )\n\nclass SEBlock(nn.Module):\n    \"\"\"\n    Squeeze-and-Excitation block from 'Squeeze-and-Excitation Networks,' https://arxiv.org/abs/1709.01507.\n\n    Parameters:\n    ----------\n    channels : int\n        Number of channels.\n    reduction : int, default 16\n        Squeeze reduction value.\n    approx_sigmoid : bool, default False\n        Whether to use approximated sigmoid function.\n    activation : function, or str, or nn.Module\n        Activation function or name of activation function.\n    \"\"\"\n    def __init__(self,\n                 channels,\n                 reduction=16,\n                 approx_sigmoid=False,\n                 activation=(lambda: nn.ReLU(inplace=True))):\n        super(SEBlock, self).__init__()\n        mid_cannels = channels // reduction\n\n        self.pool = nn.AdaptiveAvgPool2d(output_size=1)\n        self.conv1 = conv1x1(\n            in_planes=channels,\n            out_planes=mid_cannels,\n            bias=True)\n        self.activ = nn.ReLU()\n        self.conv2 = conv1x1(\n            in_planes=mid_cannels,\n            out_planes=channels,\n            bias=True)\n        self.sigmoid =  nn.Sigmoid()\n\n    def forward(self, x):\n        w = self.pool(x)\n        w = self.conv1(w)\n        w = self.activ(w)\n        w = self.conv2(w)\n        w = self.sigmoid(w)\n        x = x * w\n        return x","metadata":{"id":"nBUQTM17F6iH","execution":{"iopub.status.busy":"2023-07-19T18:35:34.012227Z","iopub.status.idle":"2023-07-19T18:35:34.012678Z","shell.execute_reply.started":"2023-07-19T18:35:34.012447Z","shell.execute_reply":"2023-07-19T18:35:34.012468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SECifar10CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(3, 64, 3, padding=1)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(64)),\n            ('conv2', nn.Conv2d(64, 64, 3)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(64)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n            ('se', SEBlock(64)),\n        ]))\n        self.layer2 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(64, 128, 3, padding=1)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(128)),\n            ('conv2', nn.Conv2d(128, 128, 3)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(128)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n            ('se', SEBlock(128)),\n        ]))\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(128 * 6 * 6, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, 10)\n        self.sigmoid = nn.Sigmoid()\n\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.sigmoid(x)\n        return x","metadata":{"id":"p0o1XfZDGSeH","execution":{"iopub.status.busy":"2023-07-19T18:35:34.014608Z","iopub.status.idle":"2023-07-19T18:35:34.015046Z","shell.execute_reply.started":"2023-07-19T18:35:34.014826Z","shell.execute_reply":"2023-07-19T18:35:34.014848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"se_model = SECifar10CNN().to(device)\nbest_se_model, se_test_accuracy, se_test_loss, se_logging_dict = train(se_model, lr=0.1)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"58yTNsDGGn4R","outputId":"98f63800-44be-4641-bbb4-d6b586557c0f","execution":{"iopub.status.busy":"2023-07-19T18:35:34.017060Z","iopub.status.idle":"2023-07-19T18:35:34.017608Z","shell.execute_reply.started":"2023-07-19T18:35:34.017321Z","shell.execute_reply":"2023-07-19T18:35:34.017346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"chDTRS07Gskf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n---\n\n\n\n---\n\n","metadata":{"id":"4Q8sc78Bwp05"}},{"cell_type":"code","source":"import torch.nn.functional as F\n","metadata":{"id":"Evk2-9LDzNLP","execution":{"iopub.status.busy":"2023-07-19T18:54:17.006051Z","iopub.execute_input":"2023-07-19T18:54:17.006353Z","iopub.status.idle":"2023-07-19T18:54:17.011335Z","shell.execute_reply.started":"2023-07-19T18:54:17.006325Z","shell.execute_reply":"2023-07-19T18:54:17.010283Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class ChannelPool(nn.Module):\n    def forward(self, x):\n        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\nclass SpatialGate(nn.Module):\n    def __init__(self):\n        super(SpatialGate, self).__init__()\n        kernel_size =7\n        self.compress = ChannelPool()\n        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n    def forward(self, x):\n        x_compress = self.compress(x)\n        x_out = self.spatial(x_compress)\n        scale = F.sigmoid(x_out) # broadcasting\n        return x * scale\nclass BasicConv(nn.Module):\n    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n        super(BasicConv, self).__init__()\n        self.out_channels = out_planes\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n        self.relu = nn.ReLU() if relu else None\n\n    def forward(self, x):\n        x = self.conv(x)\n        if self.bn is not None:\n            x = self.bn(x)\n        if self.relu is not None:\n            x = self.relu(x)\n        return x\n\nclass ECA_Spatial(nn.Module):\n    def __init__(self, gate_channels):\n        super(ECA_Spatial, self).__init__()\n        self.ChannelGate = eca_layer(gate_channels)\n        self.SpatialGate = SpatialGate()\n    def forward(self, x):\n        x_out = self.ChannelGate(x)\n        x_out = self.SpatialGate(x_out)\n        return x_out","metadata":{"id":"WbVHlhLswqXk","execution":{"iopub.status.busy":"2023-07-19T18:54:17.012795Z","iopub.execute_input":"2023-07-19T18:54:17.013642Z","iopub.status.idle":"2023-07-19T18:54:17.028700Z","shell.execute_reply.started":"2023-07-19T18:54:17.013608Z","shell.execute_reply":"2023-07-19T18:54:17.027607Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class ECASPCifar10CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(3, 64, 3, padding=1)),\n            ('att', ECA_Spatial(64)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(64)),\n            ('conv2', nn.Conv2d(64, 64, 3)),\n            ('att', ECA_Spatial(64)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(64)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n\n        ]))\n        self.layer2 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(64, 128, 3, padding=1)),\n            ('att', ECA_Spatial(128)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(128)),\n            ('conv2', nn.Conv2d(128, 128, 3)),\n            ('att', ECA_Spatial(128)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(128)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n\n        ]))\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(128 * 6 * 6, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, 10)\n        self.softmax = nn.Softmax()\n\n    def forward(self, x):\n        # print(x.shape, self.ae(x)[1].shape)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.softmax(x)\n        return x","metadata":{"id":"HYpRZYhzxFht","execution":{"iopub.status.busy":"2023-07-19T18:54:17.029939Z","iopub.execute_input":"2023-07-19T18:54:17.030548Z","iopub.status.idle":"2023-07-19T18:54:17.047428Z","shell.execute_reply.started":"2023-07-19T18:54:17.030507Z","shell.execute_reply":"2023-07-19T18:54:17.046433Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"ecasp_model = ECASPCifar10CNN().to(device)\nbest_ecaspmodel, ecasp_test_accuracy, ecasp_test_loss, ecasp_logging_dict = train(ecasp_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SVX7FXp_xN5p","outputId":"1597d67a-f342-449b-b1a2-b3f09474f21f","execution":{"iopub.status.busy":"2023-07-19T18:54:17.048738Z","iopub.execute_input":"2023-07-19T18:54:17.049213Z","iopub.status.idle":"2023-07-19T18:58:06.866583Z","shell.execute_reply.started":"2023-07-19T18:54:17.049180Z","shell.execute_reply":"2023-07-19T18:58:06.865571Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"  0%|          | 0/15 [00:00<?, ?it/s]/tmp/ipykernel_28/2666889858.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  x = self.softmax(x)\n  7%|▋         | 1/15 [00:14<03:25, 14.65s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 0, training accuracy: 0.422, training loss: 2.021 validation accuracy: 0.467, validation loss: 1.992\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 2/15 [00:29<03:14, 14.92s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 1, training accuracy: 0.508, training loss: 1.939 validation accuracy: 0.487, validation loss: 1.969\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 3/15 [00:44<02:59, 14.93s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 2, training accuracy: 0.523, training loss: 1.952 validation accuracy: 0.537, validation loss: 1.918\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 4/15 [00:59<02:45, 15.06s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 3, training accuracy: 0.539, training loss: 1.921 validation accuracy: 0.567, validation loss: 1.890\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 5/15 [01:15<02:32, 15.26s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 4, training accuracy: 0.547, training loss: 1.886 validation accuracy: 0.619, validation loss: 1.842\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 6/15 [01:30<02:17, 15.27s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 5, training accuracy: 0.617, training loss: 1.852 validation accuracy: 0.646, validation loss: 1.817\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 7/15 [01:45<02:01, 15.21s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 6, training accuracy: 0.594, training loss: 1.861 validation accuracy: 0.636, validation loss: 1.824\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 8/15 [02:01<01:47, 15.37s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 7, training accuracy: 0.609, training loss: 1.852 validation accuracy: 0.671, validation loss: 1.790\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 9/15 [02:16<01:31, 15.32s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 8, training accuracy: 0.656, training loss: 1.801 validation accuracy: 0.668, validation loss: 1.795\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 10/15 [02:32<01:16, 15.39s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 9, training accuracy: 0.656, training loss: 1.802 validation accuracy: 0.692, validation loss: 1.769\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 11/15 [02:47<01:00, 15.18s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 10, training accuracy: 0.641, training loss: 1.824 validation accuracy: 0.691, validation loss: 1.768\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 12/15 [03:02<00:45, 15.17s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 11, training accuracy: 0.789, training loss: 1.684 validation accuracy: 0.698, validation loss: 1.760\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 13/15 [03:16<00:30, 15.02s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 12, training accuracy: 0.719, training loss: 1.752 validation accuracy: 0.699, validation loss: 1.762\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 14/15 [03:32<00:15, 15.08s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 13, training accuracy: 0.742, training loss: 1.717 validation accuracy: 0.709, validation loss: 1.752\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 15/15 [03:46<00:00, 15.13s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 14, training accuracy: 0.805, training loss: 1.675 validation accuracy: 0.715, validation loss: 1.746\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n\n---\n\n","metadata":{"id":"1vDbXRI35uLB"}},{"cell_type":"code","source":"class ClarityAutoencoder(nn.Module):\n    def __init__(self, in_channels, out_channels, k=3, s=2, p=1, **kwargs):\n        super().__init__()\n        self.clarity = nn.Parameter(torch.tensor(3.))\n        self.clarity.requires_grad = True\n        self.encoder = nn.Sequential(\n            nn.Conv2d(in_channels, 12, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(12, 24, 4, stride=2, padding=1),\n            nn.ReLU(),\n\t\t\tnn.Conv2d(24, 48, 4, stride=2, padding=1),\n            nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),\n            nn.ReLU(),\n\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(12, out_channels, k, stride=s, padding=p, **kwargs),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded * x * self.clarity","metadata":{"id":"KDrNl3315164","execution":{"iopub.status.busy":"2023-07-19T18:58:06.868271Z","iopub.execute_input":"2023-07-19T18:58:06.868671Z","iopub.status.idle":"2023-07-19T18:58:06.878829Z","shell.execute_reply.started":"2023-07-19T18:58:06.868627Z","shell.execute_reply":"2023-07-19T18:58:06.877795Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class CAECACifar10CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(3, 64, 3, padding=1)),\n            ('eca1', eca_layer(64)),\n            ('ae1', ClarityAutoencoder(64, 64, output_padding=1)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(64)),\n            ('conv2', nn.Conv2d(64, 64, 3)),\n            ('eca2', eca_layer(64)),\n            ('ae2', ClarityAutoencoder(64, 64, k=3, s=3, p=3)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(64)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n        ]))\n        self.layer2 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(64, 128, 3, padding=1)),\n            ('eca1', eca_layer(128)),\n            ('ae1', ClarityAutoencoder(128, 128, s=4, output_padding=2)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(128)),\n            ('conv2', nn.Conv2d(128, 128, 3)),\n            ('eca2', eca_layer(128)),\n            ('ae2', ClarityAutoencoder(128, 128, k=2, s=4, output_padding=1)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(128)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n        ]))\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(128 * 6 * 6, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, 10)\n        self.softmax = nn.Softmax(1)\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.softmax(x)\n        return x","metadata":{"id":"nkp6QjT_5uwo","execution":{"iopub.status.busy":"2023-07-19T18:58:06.880205Z","iopub.execute_input":"2023-07-19T18:58:06.881043Z","iopub.status.idle":"2023-07-19T18:58:06.897345Z","shell.execute_reply.started":"2023-07-19T18:58:06.881006Z","shell.execute_reply":"2023-07-19T18:58:06.896401Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"caeca_model = CAECACifar10CNN().to(device)\nbest_caecamodel, caeca_test_accuracy, caeca_test_loss, caeca_logging_dict = train(caeca_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fVJ1G8AW6fmI","outputId":"12c046ca-2c31-4745-caed-725cff39f05f","execution":{"iopub.status.busy":"2023-07-19T18:59:44.362638Z","iopub.execute_input":"2023-07-19T18:59:44.363008Z","iopub.status.idle":"2023-07-19T19:04:23.706414Z","shell.execute_reply.started":"2023-07-19T18:59:44.362979Z","shell.execute_reply":"2023-07-19T19:04:23.705419Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"  7%|▋         | 1/15 [00:19<04:38, 19.87s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 0, training accuracy: 0.570, training loss: 1.920 validation accuracy: 0.494, validation loss: 1.967\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 2/15 [00:37<04:03, 18.73s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 1, training accuracy: 0.570, training loss: 1.885 validation accuracy: 0.606, validation loss: 1.857\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 3/15 [00:57<03:51, 19.31s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 2, training accuracy: 0.586, training loss: 1.870 validation accuracy: 0.624, validation loss: 1.832\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 4/15 [01:16<03:29, 19.04s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 3, training accuracy: 0.656, training loss: 1.812 validation accuracy: 0.678, validation loss: 1.785\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 5/15 [01:34<03:06, 18.61s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 4, training accuracy: 0.672, training loss: 1.789 validation accuracy: 0.702, validation loss: 1.759\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 6/15 [01:52<02:45, 18.44s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 5, training accuracy: 0.719, training loss: 1.736 validation accuracy: 0.719, validation loss: 1.744\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 7/15 [02:10<02:25, 18.19s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 6, training accuracy: 0.656, training loss: 1.805 validation accuracy: 0.728, validation loss: 1.738\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 8/15 [02:28<02:07, 18.26s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 7, training accuracy: 0.742, training loss: 1.724 validation accuracy: 0.738, validation loss: 1.719\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 9/15 [02:46<01:49, 18.23s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 8, training accuracy: 0.812, training loss: 1.660 validation accuracy: 0.755, validation loss: 1.708\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 10/15 [03:04<01:30, 18.07s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 9, training accuracy: 0.648, training loss: 1.798 validation accuracy: 0.758, validation loss: 1.704\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 11/15 [03:23<01:13, 18.32s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 10, training accuracy: 0.711, training loss: 1.739 validation accuracy: 0.765, validation loss: 1.695\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 12/15 [03:41<00:54, 18.22s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 11, training accuracy: 0.805, training loss: 1.675 validation accuracy: 0.770, validation loss: 1.691\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 13/15 [03:59<00:36, 18.30s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 12, training accuracy: 0.812, training loss: 1.659 validation accuracy: 0.785, validation loss: 1.678\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 14/15 [04:17<00:18, 18.22s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 13, training accuracy: 0.852, training loss: 1.617 validation accuracy: 0.781, validation loss: 1.681\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 15/15 [04:36<00:00, 18.41s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 14, training accuracy: 0.797, training loss: 1.661 validation accuracy: 0.788, validation loss: 1.672\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"6NTC_lFO8O5n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n---\n\n","metadata":{"id":"Jfu_-BqTGY4k"}},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"id":"DHa8Vd0CGZaK","execution":{"iopub.status.busy":"2023-07-19T18:35:34.038083Z","iopub.status.idle":"2023-07-19T18:35:34.038938Z","shell.execute_reply.started":"2023-07-19T18:35:34.038692Z","shell.execute_reply":"2023-07-19T18:35:34.038717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for m in (best_caecamodel, ecasp_model, eca_model,aeca_model, ae_model, model):\n    print(m.__class__, f'{count_parameters(m):,.0f}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_DCVq1_XG2pl","outputId":"06a3aa35-4b00-4055-aeb7-df2d39bd4fb5","execution":{"iopub.status.busy":"2023-07-19T18:35:34.040300Z","iopub.status.idle":"2023-07-19T18:35:34.041097Z","shell.execute_reply.started":"2023-07-19T18:35:34.040853Z","shell.execute_reply":"2023-07-19T18:35:34.040877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n---\n\n","metadata":{"id":"h90RdZQ_J21m"}},{"cell_type":"code","source":"class DeeperCifar10CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(3, 64, 3, padding=1)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(64)),\n            ('conv2', nn.Conv2d(64, 64, 3)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(64)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n\n        ]))\n        self.layer2 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(64, 128, 3, padding=1)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(128)),\n            ('conv2', nn.Conv2d(128, 128, 3)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(128)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n\n        ]))\n\n        self.layer3 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(128, 256, 3, padding=1)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(256)),\n            ('conv2', nn.Conv2d(256, 256, 3)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(256)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n\n        ]))\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(256 * 6 * 3, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, 10)\n        self.softmax = nn.Softmax()\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.softmax(x)\n        return x","metadata":{"id":"Y6kSnPEAHnK5","execution":{"iopub.status.busy":"2023-07-19T19:04:23.767727Z","iopub.execute_input":"2023-07-19T19:04:23.768100Z","iopub.status.idle":"2023-07-19T19:04:23.782054Z","shell.execute_reply.started":"2023-07-19T19:04:23.768066Z","shell.execute_reply":"2023-07-19T19:04:23.781049Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"deeper_model = DeeperCifar10CNN().to(device)\nbest_deepermodel, deeper_test_accuracy, deeper_test_loss, deeper_logging_dict = train(deeper_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vdWpQ18KKIuL","outputId":"50227468-e209-4d08-942c-397a28dd6cc3","execution":{"iopub.status.busy":"2023-07-19T19:04:23.784890Z","iopub.execute_input":"2023-07-19T19:04:23.785506Z","iopub.status.idle":"2023-07-19T19:07:57.191028Z","shell.execute_reply.started":"2023-07-19T19:04:23.785469Z","shell.execute_reply":"2023-07-19T19:07:57.189993Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"  0%|          | 0/15 [00:00<?, ?it/s]/tmp/ipykernel_28/2522588928.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  x = self.softmax(x)\n  7%|▋         | 1/15 [00:14<03:22, 14.43s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 0, training accuracy: 0.562, training loss: 1.889 validation accuracy: 0.536, validation loss: 1.930\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 2/15 [00:28<03:04, 14.21s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 1, training accuracy: 0.586, training loss: 1.884 validation accuracy: 0.606, validation loss: 1.860\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 3/15 [00:42<02:48, 14.05s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 2, training accuracy: 0.586, training loss: 1.882 validation accuracy: 0.638, validation loss: 1.819\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 4/15 [00:56<02:35, 14.10s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 3, training accuracy: 0.594, training loss: 1.856 validation accuracy: 0.662, validation loss: 1.796\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 5/15 [01:10<02:19, 13.96s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 4, training accuracy: 0.625, training loss: 1.832 validation accuracy: 0.689, validation loss: 1.775\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 6/15 [01:24<02:06, 14.05s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 5, training accuracy: 0.664, training loss: 1.806 validation accuracy: 0.697, validation loss: 1.762\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 7/15 [01:38<01:51, 13.96s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 6, training accuracy: 0.742, training loss: 1.731 validation accuracy: 0.722, validation loss: 1.741\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 8/15 [01:52<01:38, 14.09s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 7, training accuracy: 0.688, training loss: 1.774 validation accuracy: 0.725, validation loss: 1.736\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 9/15 [02:06<01:24, 14.02s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 8, training accuracy: 0.695, training loss: 1.784 validation accuracy: 0.740, validation loss: 1.722\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 10/15 [02:20<01:09, 13.90s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 9, training accuracy: 0.656, training loss: 1.797 validation accuracy: 0.755, validation loss: 1.707\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 11/15 [02:34<00:56, 14.03s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 10, training accuracy: 0.695, training loss: 1.762 validation accuracy: 0.759, validation loss: 1.704\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 12/15 [02:47<00:41, 13.89s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 11, training accuracy: 0.773, training loss: 1.681 validation accuracy: 0.766, validation loss: 1.697\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 13/15 [03:02<00:27, 13.98s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 12, training accuracy: 0.688, training loss: 1.769 validation accuracy: 0.757, validation loss: 1.703\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 14/15 [03:15<00:13, 13.93s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 13, training accuracy: 0.844, training loss: 1.633 validation accuracy: 0.772, validation loss: 1.690\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 15/15 [03:30<00:00, 14.04s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 14, training accuracy: 0.742, training loss: 1.721 validation accuracy: 0.779, validation loss: 1.683\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"count_parameters(deeper_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qmnAKGYHKdrF","outputId":"fea0b167-8022-4712-dceb-f3bef23e507d","execution":{"iopub.status.busy":"2023-07-19T18:35:34.046799Z","iopub.status.idle":"2023-07-19T18:35:34.047697Z","shell.execute_reply.started":"2023-07-19T18:35:34.047423Z","shell.execute_reply":"2023-07-19T18:35:34.047451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n---\n\n\n\n---\n\n","metadata":{"id":"TNxLL616Q5y4"}},{"cell_type":"code","source":"class LinearAutoencoder(nn.Module):\n    def __init__(self, input_size=32 * 32, layers=[128, 64, 12, 3]):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_size, layers[0]),\n            nn.ReLU(),\n            nn.Linear(layers[0], layers[1]),\n            nn.ReLU(),\n            nn.Linear(layers[1], layers[2]),\n        )\n\n        self.decoder = nn.Sequential(\n            nn.Linear(layers[2], layers[1]),\n            nn.ReLU(),\n            nn.Linear(layers[1], layers[0]),\n            nn.ReLU(),\n            nn.Linear(layers[0], input_size),\n            nn.Sigmoid(),\n        )\n        for layer in [*self.encoder.modules(), *self.decoder.modules()]:\n            if isinstance(layer, nn.Linear):\n                nn.init.kaiming_normal_(layer.weight)\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return x * decoded * 2.0","metadata":{"id":"iBo5Uh1nQ6d_","execution":{"iopub.status.busy":"2023-07-19T19:07:57.192499Z","iopub.execute_input":"2023-07-19T19:07:57.192869Z","iopub.status.idle":"2023-07-19T19:07:57.202628Z","shell.execute_reply.started":"2023-07-19T19:07:57.192835Z","shell.execute_reply":"2023-07-19T19:07:57.201678Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"class LAECACifar10CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(3, 64, 3, padding=1)),\n            ('eca1', eca_layer(64)),\n            ('ae1', LinearAutoencoder(32)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(64)),\n            ('conv2', nn.Conv2d(64, 64, 3)),\n            ('eca2', eca_layer(64)),\n#             ('ae2', LinearAutoencoder(30)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(64)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n        ]))\n        self.layer2 = nn.Sequential(OrderedDict([\n            ('conv1', nn.Conv2d(64, 128, 3, padding=1)),\n            ('eca1', eca_layer(128)),\n            ('ae1', LinearAutoencoder(15)),\n            ('relu1', nn.ReLU()),\n            ('bn1', nn.BatchNorm2d(128)),\n            ('conv2', nn.Conv2d(128, 128, 3)),\n            ('eca2', eca_layer(128)),\n#             ('ae2', LinearAutoencoder(13)),\n            ('relu2', nn.ReLU()),\n            ('bn2', nn.BatchNorm2d(128)),\n            ('maxpool1', nn.MaxPool2d(2)),\n            ('dropout1', nn.Dropout2d(0.25)),\n        ]))\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(128 * 6 * 6, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, 10)\n        self.softmax = nn.Softmax(1)\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.softmax(x)\n        return x","metadata":{"id":"G-1ZQ7m3RBUF","execution":{"iopub.status.busy":"2023-07-19T19:07:57.204265Z","iopub.execute_input":"2023-07-19T19:07:57.205050Z","iopub.status.idle":"2023-07-19T19:07:57.219496Z","shell.execute_reply.started":"2023-07-19T19:07:57.205012Z","shell.execute_reply":"2023-07-19T19:07:57.218450Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"laeca_model = LAECACifar10CNN().to(device)\nbest_laecamodel, laeca_test_accuracy, laeca_test_loss, laeca_logging_dict = train(laeca_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"outputId":"2aba2f17-7af7-485a-95dd-c568c024759a","id":"Ugnmwi8aRBUG","execution":{"iopub.status.busy":"2023-07-19T19:07:57.220728Z","iopub.execute_input":"2023-07-19T19:07:57.221212Z","iopub.status.idle":"2023-07-19T19:13:53.870545Z","shell.execute_reply.started":"2023-07-19T19:07:57.221180Z","shell.execute_reply":"2023-07-19T19:13:53.869514Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"  7%|▋         | 1/15 [00:23<05:34, 23.91s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 0, training accuracy: 0.461, training loss: 1.994 validation accuracy: 0.467, validation loss: 1.991\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 2/15 [00:47<05:06, 23.54s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 1, training accuracy: 0.547, training loss: 1.931 validation accuracy: 0.518, validation loss: 1.943\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 3/15 [01:10<04:42, 23.56s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 2, training accuracy: 0.578, training loss: 1.894 validation accuracy: 0.566, validation loss: 1.892\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 4/15 [01:34<04:19, 23.56s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 3, training accuracy: 0.680, training loss: 1.803 validation accuracy: 0.655, validation loss: 1.809\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 5/15 [01:57<03:54, 23.50s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 4, training accuracy: 0.609, training loss: 1.830 validation accuracy: 0.692, validation loss: 1.773\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 6/15 [02:21<03:31, 23.50s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 5, training accuracy: 0.695, training loss: 1.758 validation accuracy: 0.697, validation loss: 1.764\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 7/15 [02:44<03:08, 23.53s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 6, training accuracy: 0.688, training loss: 1.777 validation accuracy: 0.732, validation loss: 1.731\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 8/15 [03:08<02:44, 23.55s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 7, training accuracy: 0.734, training loss: 1.735 validation accuracy: 0.745, validation loss: 1.718\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 9/15 [03:31<02:20, 23.47s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 8, training accuracy: 0.719, training loss: 1.741 validation accuracy: 0.757, validation loss: 1.704\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 10/15 [03:55<01:57, 23.48s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 9, training accuracy: 0.750, training loss: 1.723 validation accuracy: 0.749, validation loss: 1.712\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 11/15 [04:18<01:34, 23.52s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 10, training accuracy: 0.734, training loss: 1.717 validation accuracy: 0.762, validation loss: 1.701\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 12/15 [04:42<01:10, 23.56s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 11, training accuracy: 0.742, training loss: 1.711 validation accuracy: 0.766, validation loss: 1.697\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 13/15 [05:05<00:46, 23.48s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 12, training accuracy: 0.805, training loss: 1.667 validation accuracy: 0.783, validation loss: 1.681\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 14/15 [05:29<00:23, 23.49s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 13, training accuracy: 0.859, training loss: 1.610 validation accuracy: 0.784, validation loss: 1.677\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 15/15 [05:52<00:00, 23.52s/it]","output_type":"stream"},{"name":"stdout","text":"\nepoch = 14, training accuracy: 0.727, training loss: 1.732 validation accuracy: 0.787, validation loss: 1.673\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"count_parameters(laeca_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8Gk9Sn7RbFD","outputId":"5f039e8c-e116-4119-e5b1-a012ce60a121","execution":{"iopub.status.busy":"2023-07-19T18:35:34.055674Z","iopub.status.idle":"2023-07-19T18:35:34.056454Z","shell.execute_reply.started":"2023-07-19T18:35:34.056208Z","shell.execute_reply":"2023-07-19T18:35:34.056230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GradCam","metadata":{"id":"X9AqducyUys8"}},{"cell_type":"markdown","source":"Docs: https://jacobgil.github.io/pytorch-gradcam-book/introduction.html","metadata":{"id":"_Au4GRC9U-B6"}},{"cell_type":"code","source":"%pip install grad-cam --quiet\nfrom pytorch_grad_cam import GradCAM\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pAGh5wv7U6_l","outputId":"adbe3a8f-ef01-4dde-d405-4fdb6a31298a","execution":{"iopub.status.busy":"2023-07-19T18:35:34.057851Z","iopub.status.idle":"2023-07-19T18:35:34.058715Z","shell.execute_reply.started":"2023-07-19T18:35:34.058472Z","shell.execute_reply":"2023-07-19T18:35:34.058495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes_names = {i: c for i, c in enumerate (('airplane', 'automobile', 'bird', 'cat', 'deer',\n                                              'dog', 'frog', 'horse', 'ship', 'truck',))}\n\ndef show_activations(model, target_layers, image_number: int | None = None, use_cuda=True):\n    model.eval()\n    if image_number == None:\n        img, label = cifar10['train'][np.random.randint(350)]\n    else:\n        img, label = cifar10['train'][image_number]\n    input_tensor = img.unsqueeze(0)\n    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=use_cuda)\n    targets = [ClassifierOutputTarget(label)] if label else None\n    grayscale_cam = cam(input_tensor, targets)\n    grayscale_cam = grayscale_cam[0, :]\n    def normalize(img):\n        return ((img - img.min()) / (img.max() - img.min()))\n\n    visualization = show_cam_on_image(normalize(torch.permute(img, (1, 2, 0))).numpy(), grayscale_cam, use_rgb=True)\n\n    fig, axs = plt.subplots(1, 2)\n    axs = axs.ravel()\n    axs[0].imshow(torch.permute(img, (1, 2, 0)))\n    axs[0].axis('off')\n    axs[1].imshow(visualization)\n    axs[1].axis('off')\n    plt.suptitle(classes_names[label])\n","metadata":{"id":"i0r-_t3JU0_M","execution":{"iopub.status.busy":"2023-07-19T18:35:34.060091Z","iopub.status.idle":"2023-07-19T18:35:34.060896Z","shell.execute_reply.started":"2023-07-19T18:35:34.060635Z","shell.execute_reply":"2023-07-19T18:35:34.060658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n---\n\n","metadata":{"id":"hjAcgnS5ZAdO"}},{"cell_type":"code","source":"!rm -r './models/cnn/'","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:16:31.357313Z","iopub.execute_input":"2023-07-19T19:16:31.358234Z","iopub.status.idle":"2023-07-19T19:16:32.382081Z","shell.execute_reply.started":"2023-07-19T19:16:31.358186Z","shell.execute_reply":"2023-07-19T19:16:32.380450Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"import os\nimport pickle\nfrom datetime import datetime\n# os.mkdir('./models/')\ndef save_model_and_data(name, model, test_accuracy, test_loss, logging_dict):\n    os.mkdir(f'./models/{name}')\n    torch.save(model.state_dict(), f'./models/{name}/{name}.pt')\n    data = {'test_accuracy': test_accuracy,\n            'test_loss': test_loss,\n            'logging_dict': logging_dict,\n            'datetime': datetime.now()}\n    with open(f'./models/{name}/{name}.pkl', 'wb') as f:\n        pickle.dump(data, f)","metadata":{"id":"HONxuk6wU_a8","execution":{"iopub.status.busy":"2023-07-19T19:16:02.212558Z","iopub.execute_input":"2023-07-19T19:16:02.213006Z","iopub.status.idle":"2023-07-19T19:16:02.223857Z","shell.execute_reply.started":"2023-07-19T19:16:02.212969Z","shell.execute_reply":"2023-07-19T19:16:02.222564Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"models_data = {\n    'cnn': [best_model, test_accuracy, test_loss, logging_dict],\n    'autoencoder': [best_ae_model, ae_test_accuracy, ae_test_loss, ae_logging_dict],\n    'eca': [best_eca_model, eca_test_accuracy, eca_test_loss, eca_logging_dict],\n    'autoencoder_eca': [best_aeca_model, aeca_test_accuracy, aeca_test_loss, aeca_logging_dict],\n    'c_autoencoder_eca': [best_caecamodel, caeca_test_accuracy, caeca_test_loss, caeca_logging_dict],\n    'linear_autoencoder_eca': [best_laecamodel, laeca_test_accuracy, laeca_test_loss, laeca_logging_dict],\n    'eca_spatial': [best_ecaspmodel, ecasp_test_accuracy, ecasp_test_loss, ecasp_logging_dict],\n    'deeper_cnn': [best_deepermodel, deeper_test_accuracy, deeper_test_loss, deeper_logging_dict],\n}\n\nfor md in models_data:\n    save_model_and_data(md, *models_data[md])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"TbouJ2ryZH_3","outputId":"ce524864-03e1-4fca-d5b3-c9d8557027b6","execution":{"iopub.status.busy":"2023-07-19T19:16:37.120064Z","iopub.execute_input":"2023-07-19T19:16:37.120473Z","iopub.status.idle":"2023-07-19T19:16:37.311799Z","shell.execute_reply.started":"2023-07-19T19:16:37.120435Z","shell.execute_reply":"2023-07-19T19:16:37.310672Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"!zip -r models.zip models/","metadata":{"execution":{"iopub.status.busy":"2023-07-19T19:18:57.433085Z","iopub.execute_input":"2023-07-19T19:18:57.433526Z","iopub.status.idle":"2023-07-19T19:19:03.524040Z","shell.execute_reply.started":"2023-07-19T19:18:57.433487Z","shell.execute_reply":"2023-07-19T19:19:03.522694Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"  adding: models/ (stored 0%)\n  adding: models/eca/ (stored 0%)\n  adding: models/eca/eca.pt (deflated 8%)\n  adding: models/eca/eca.pkl (deflated 72%)\n  adding: models/linear_autoencoder_eca/ (stored 0%)\n  adding: models/linear_autoencoder_eca/linear_autoencoder_eca.pt (deflated 8%)\n  adding: models/linear_autoencoder_eca/linear_autoencoder_eca.pkl (deflated 72%)\n  adding: models/deeper_cnn/ (stored 0%)\n  adding: models/deeper_cnn/deeper_cnn.pt (deflated 8%)\n  adding: models/deeper_cnn/deeper_cnn.pkl (deflated 72%)\n  adding: models/autoencoder/ (stored 0%)\n  adding: models/autoencoder/autoencoder.pkl (deflated 72%)\n  adding: models/autoencoder/autoencoder.pt (deflated 8%)\n  adding: models/eca_spatial/ (stored 0%)\n  adding: models/eca_spatial/eca_spatial.pt (deflated 8%)\n  adding: models/eca_spatial/eca_spatial.pkl (deflated 71%)\n  adding: models/c_autoencoder_eca/ (stored 0%)\n  adding: models/c_autoencoder_eca/c_autoencoder_eca.pkl (deflated 72%)\n  adding: models/c_autoencoder_eca/c_autoencoder_eca.pt (deflated 8%)\n  adding: models/autoencoder_eca/ (stored 0%)\n  adding: models/autoencoder_eca/autoencoder_eca.pkl (deflated 72%)\n  adding: models/autoencoder_eca/autoencoder_eca.pt (deflated 8%)\n  adding: models/cnn/ (stored 0%)\n  adding: models/cnn/cnn.pkl (deflated 72%)\n  adding: models/cnn/cnn.pt (deflated 8%)\n","output_type":"stream"}]}]}